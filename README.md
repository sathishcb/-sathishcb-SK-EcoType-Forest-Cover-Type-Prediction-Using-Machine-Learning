# ğŸŒ² EcoType: Forest Cover Type Prediction Using Machine Learning

## ğŸ“Œ Project Overview
EcoType is a machine learning classification project that predicts the forest cover type of a geographical area using cartographic and environmental features such as elevation, slope, soil type, and distance measures. The project supports environmental monitoring, forestry management, and land-use planning by providing an automated and reliable prediction system.

## ğŸ¯ Problem Statement
To develop a machine learning classification model that accurately predicts the forest cover type based on cartographic variables, enabling efficient forest resource management and ecological analysis.

## ğŸŒ¿ Domain
Environmental Data & Geospatial Predictive Modeling

## ğŸ“š Skills & Technologies Used
- Exploratory Data Analysis (EDA)
- Data Cleaning & Preprocessing
- Skewness Detection & Handling
- Feature Engineering
- Class Imbalance Handling (SMOTE)
- Classification Models
- Model Evaluation
- Hyperparameter Tuning
- Streamlit Application Development
- Model Deployment

Libraries & Tools:
Python, Pandas, NumPy, Scikit-learn, XGBoost, Imbalanced-learn, Matplotlib, Seaborn, Streamlit, Joblib

## ğŸ“Š Dataset Information
- Source: Forest Cover Type Dataset
- Size: 145,891 rows Ã— 13 columns
- Target Variable: Cover_Type (7 classes)

## ğŸ” Exploratory Data Analysis (EDA)
EDA was performed in a separate Jupyter notebook to understand feature distributions, skewness, class imbalance, correlations, and feature importance.

Notebook:
- notebooks/EDA_Forest_Cover.ipynb

## âš™ï¸ Data Preprocessing
- Verified no missing values
- Detected skewed features using skewness metrics
- Applied transformations where required
- Encoded target variable
- Ensured consistent feature selection

## âš–ï¸ Class Imbalance Handling
SMOTE (Synthetic Minority Oversampling Technique) was applied on the training dataset to balance class distribution.

## ğŸ§  Model Building & Evaluation

Models trained:
- Logistic Regression
- Decision Tree
- K-Nearest Neighbors (KNN)
- Random Forest
- XGBoost

Evaluation metrics:
- Accuracy
- Confusion Matrix
- Classification Report

### ğŸ“ˆ Model Comparison Summary

| Model | Accuracy |
|------|----------|
| Logistic Regression | 0.72 |
| Decision Tree | 0.97 |
| KNN | 0.95 |
| Random Forest | 0.99 |
| XGBoost | 0.99 |

Best Model Selected: Random Forest

Notebook:
- notebooks/Model_Comparison.ipynb

## ğŸ”§ Hyperparameter Tuning
RandomizedSearchCV was applied to the Random Forest model to optimize performance while keeping training time reasonable.

## ğŸ’¾ Model Saving
Saved artifacts using joblib:
- forest_cover_model.pkl
- selected_features.pkl
- label_encoder.pkl

## ğŸŒ Streamlit Application
A Streamlit web application was developed for single-instance prediction using manual numeric inputs.

Run the app:
streamlit run app.py
			
## ğŸ“ Project Structure

```text
Eco_Type_Forest_Prediction/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ covtype.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ EDA_Forest_Cover.ipynb
â”‚   â””â”€â”€ Model_Comparison.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ skewness_handler.py
â”‚   â”œâ”€â”€ imbalance_handler.py
â”‚   â”œâ”€â”€ feature_selection.py
â”‚   â””â”€â”€ model_training.py
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ app.py
â”œâ”€â”€ forest_cover_model.pkl
â”œâ”€â”€ selected_features.pkl
â”œâ”€â”€ label_encoder.pkl
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ Conclusion
EcoType demonstrates a complete end-to-end machine learning pipelineâ€”from data analysis and model comparison to deploymentâ€”providing a practical solution for forest cover type prediction.

## ğŸ‘¤ Author
Sathishkumar CB
